{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(\n",
    "        url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download \"\n",
    "              \"and extraction.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
    "        num_spam, random_state=123\n",
    "    )\n",
    "    balanced_df = pd.concat([\n",
    "        ham_subset, df[df[\"Label\"] == \"spam\"]\n",
    "    ])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0 , \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "\n",
    "    df = df.sample(\n",
    "        frac=1, random_state=123\n",
    "    ).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(\n",
    "    balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None,\n",
    "                 pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * \n",
    "            (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx,\n",
    "                         max_new_tokens, context_size): \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi Head Attention with Weight Splits\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "    \n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean ) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, \n",
    "                 context_length, dropout, num_heads, qkv_bias=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert( d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "            \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), \n",
    "                       diagonal=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        \n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_book = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        \n",
    "        attn_scores.masked_fill_(mask_book, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores/ keys.shape[-1] ** -.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        \n",
    "        context_vec = context_vec.contiguous().view(\n",
    "            b, num_tokens, self.d_out\n",
    "        )\n",
    "        \n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec\n",
    "        \n",
    "\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers  = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedFoward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(*[\n",
    "            TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])\n",
    "        ])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, in_idx):\n",
    "        \n",
    "        batch_size , seq_len = in_idx.shape\n",
    "        \n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        \n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "\n",
    "    ## TODO: WHY final_norm?\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                          \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedFoward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you make to get rid of the way I'll make.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "import math\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'s a. .\n",
      "\n",
      "The game of the game.\n",
      "\n",
      "\n",
      ". The game\n",
      "Theatre website\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG[\"emb_dim\"], \n",
    "    out_features=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n",
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.6703,  7.0631],\n",
      "         [-2.4645,  6.2451],\n",
      "         [-4.0764,  4.6433]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n",
      "Last output token: tensor([[-4.0764,  4.6433]])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape)\n",
    "\n",
    "\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-4.0764,  4.6433]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (\n",
    "                (predicted_labels == target_batch).sum().item()\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 46.25%\n",
      "Test accuracy: 47.50%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.770\n",
      "Validation loss: 2.741\n",
      "Test loss: 2.564\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "        model, train_loader, val_loader, optimizer, device,\n",
    "        num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.506, Val loss 2.627\n",
      "Ep 1 (Step 000050): Train loss 0.676, Val loss 0.708\n",
      "Ep 1 (Step 000100): Train loss 0.651, Val loss 0.689\n",
      "Training accuracy: 62.50% | Validation accuracy: 52.50%\n",
      "Ep 2 (Step 000150): Train loss 0.619, Val loss 0.705\n",
      "Ep 2 (Step 000200): Train loss 0.754, Val loss 0.683\n",
      "Ep 2 (Step 000250): Train loss 0.693, Val loss 0.678\n",
      "Training accuracy: 60.00% | Validation accuracy: 62.50%\n",
      "Ep 3 (Step 000300): Train loss 0.583, Val loss 0.675\n",
      "Ep 3 (Step 000350): Train loss 0.602, Val loss 0.682\n",
      "Training accuracy: 85.00% | Validation accuracy: 65.00%\n",
      "Ep 4 (Step 000400): Train loss 0.504, Val loss 0.687\n",
      "Ep 4 (Step 000450): Train loss 0.556, Val loss 0.663\n",
      "Ep 4 (Step 000500): Train loss 0.796, Val loss 0.671\n",
      "Training accuracy: 72.50% | Validation accuracy: 65.00%\n",
      "Ep 5 (Step 000550): Train loss 0.501, Val loss 0.679\n",
      "Ep 5 (Step 000600): Train loss 0.604, Val loss 0.681\n",
      "Training accuracy: 72.50% | Validation accuracy: 65.00%\n",
      "Training completed in 3.92 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
    "    train_classifier_simple(\n",
    "        model, train_loader, val_loader, optimizer, device,\n",
    "        num_epochs=num_epochs, eval_freq=50,\n",
    "        eval_iter=5\n",
    "    )\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVlElEQVR4nO3deVxU9f748dfMsO+LrMrmhoqAiBvuhbmVN7Nu5ddMW3+WS17zVmYuWV3bLOt6s7TSytIWtSzNxBQt9w1FxR0FFURAdhlg5vz+GBgccQFFZoD38/E4D+d8zvaeD8j7fD5n+agURVEQQgghhEVSmzsAIYQQQlyfJGohhBDCgkmiFkIIISyYJGohhBDCgkmiFkIIISyYJGohhBDCgkmiFkIIISyYJGohhBDCgkmiFkIIISyYJGohRLX07duXiRMnmjsMIRodSdRC1JHRo0ejUqmqTAMHDjR3aEIIC2Zl7gCEaEwGDhzIokWLTMpsbW3NFI0Qoj6QFrUQdcjW1hZfX1+Tyd3dHYD4+HhsbGz466+/jOvPmTOHJk2akJaWBsDatWvp2bMnbm5ueHp6ct9993Hy5Enj+qdPn0alUvHDDz/Qq1cv7O3t6dy5M8eOHWPXrl106tQJJycnBg4cyMWLF43bjR49mqFDh/L666/j7e2Ni4sL/+///T9KSkqu+11KSkp46aWXaNq0KY6OjnTt2pX4+Hjj8jNnzjBkyBDc3d1xdHQkLCyMNWvWXHd/n3zyCa1atcLOzg4fHx8eeugh4zJFUXj33Xdp3rw59vb2REZG8tNPP5lsf/jwYQYPHoyTkxM+Pj6MHDmSzMxM4/K+ffsyYcIEXnrpJTw8PPD19WXmzJnXjUcISyGJWggLUXENeOTIkeTm5rJ//36mTp3KwoUL8fPzA6CwsJBJkyaxa9cu/vzzT9RqNQ888AB6vd5kXzNmzOC1115j7969WFlZMXz4cF566SU++ugj/vrrL06ePMn06dNNtvnzzz9JSkpi48aNLF26lJUrV/L6669fN94nnniCLVu2sGzZMg4cOMA///lPBg4cyPHjxwEYO3YsWq2WzZs3k5iYyDvvvIOTk9M197V7924mTJjArFmzOHr0KGvXrqV3797G5a+99hqLFi1i/vz5HDp0iH/961889thjbNq0CYC0tDT69OlDhw4d2L17N2vXruXChQs8/PDDJsf56quvcHR0ZMeOHbz77rvMmjWLuLi4av6EhDATRQhRJ0aNGqVoNBrF0dHRZJo1a5ZxHa1Wq0RFRSkPP/ywEhYWpjz99NM33GdGRoYCKImJiYqiKEpycrICKJ9//rlxnaVLlyqA8ueffxrLZs+erYSGhprE5uHhoRQWFhrL5s+frzg5OSk6nU5RFEXp06eP8sILLyiKoignTpxQVCqVcu7cOZN4YmNjlSlTpiiKoijh4eHKzJkzq1U3y5cvV1xcXJS8vLwqywoKChQ7Oztl69atJuVPPfWUMnz4cEVRFGXatGlK//79TZanpqYqgHL06FFj/D179jRZp3PnzsrLL79crRiFMBe5Ri1EHbrrrruYP3++SZmHh4fxs42NDUuWLCEiIoKgoCDmzp1rsu7JkyeZNm0a27dvJzMz09iSTklJoX379sb1IiIijJ99fHwACA8PNynLyMgw2XdkZCQODg7G+ZiYGAoKCkhNTSUoKMhk3b1796IoCq1btzYp12q1eHp6AjBhwgSee+451q1bR79+/XjwwQdN4rrSPffcQ1BQEM2bN2fgwIEMHDiQBx54AAcHBw4fPkxxcTH33HOPyTYlJSVERUUBsGfPHjZu3HjNFvvJkyeNcV59fD8/vyr1IISlkUQtRB1ydHSkZcuWN1xn69atAGRnZ5OdnY2jo6Nx2ZAhQwgICGDhwoX4+/uj1+tp3759lWvJ1tbWxs8qleqaZVd3l19PxfZX0uv1aDQa9uzZg0ajMVlWkSyffvppBgwYwOrVq1m3bh2zZ89mzpw5jB8/vsr+nJ2d2bt3L/Hx8axbt47p06czc+ZMdu3aZYxz9erVNG3a1GS7ihvx9Ho9Q4YM4Z133qmy74rLBlfXQcV3q249CGEukqiFsCAnT57kX//6FwsXLuSHH37g8ccfN16LzsrKIikpic8++4xevXoB8Pfff9fasffv38/ly5ext7cHYPv27Tg5OdGsWbMq60ZFRaHT6cjIyDDGci0BAQGMGTOGMWPGMGXKFBYuXHjNRA1gZWVFv3796NevHzNmzMDNzY0NGzZwzz33YGtrS0pKCn369Lnmth07dmT58uUEBwdjZSV/1kTDIr/RQtQhrVZLenq6SZmVlRVNmjRBp9MxcuRI+vfvzxNPPMGgQYMIDw9nzpw5/Pvf/8bd3R1PT08WLFiAn58fKSkpvPLKK7UWW0lJCU899RSvvfYaZ86cYcaMGYwbNw61uuo9p61bt2bEiBE8/vjjzJkzh6ioKDIzM9mwYQPh4eEMHjyYiRMnMmjQIFq3bs2lS5fYsGEDbdu2veaxf/vtN06dOkXv3r1xd3dnzZo16PV6QkNDcXZ2ZvLkyfzrX/9Cr9fTs2dP8vLy2Lp1K05OTowaNYqxY8eycOFChg8fzr///W+aNGnCiRMnWLZsGQsXLqzS6heiPpFELUQdWrt2rUlXLEBoaChHjhzhrbfe4vTp0/z6668A+Pr68vnnn/Pwww9zzz330KFDB5YtW8aECRNo3749oaGhfPzxx/Tt27dWYouNjaVVq1b07t0brVbLo48+esPHlxYtWsSbb77Jiy++yLlz5/D09CQmJobBgwcDoNPpGDt2LGfPnsXFxYWBAwfy4YcfXnNfbm5urFixgpkzZ1JcXEyrVq1YunQpYWFhALzxxht4e3sze/ZsTp06hZubGx07duTVV18FwN/fny1btvDyyy8zYMAAtFotQUFBDBw48JonGkLUJypFURRzByGEMK/Ro0eTk5PDzz//bO5QhBBXkVNNIYQQwoJJohZCCCEsmHR9CyGEEBZMWtRCCCGEBZNELYQQQlgwSdRCCCGEBZNEfRs++eQTQkJCsLOzIzo62mR4woZk8+bNDBkyBH9/f1QqVZVHeBRFYebMmfj7+2Nvb0/fvn05dOiQyTparZbx48fTpEkTHB0d+cc//sHZs2dN1rl06RIjR47E1dUVV1dXRo4cSU5Ozh3+drVj9uzZdO7cGWdnZ7y9vRk6dChHjx41Waex19P8+fOJiIjAxcUFFxcXYmJi+P33343LG3v9XMvs2bNRqVRMnDjRWCb1BDNnzkSlUplMvr6+xuUNro7MNRpIfbds2TLF2tpaWbhwoXL48GHlhRdeUBwdHZUzZ86YO7Rat2bNGmXq1KnK8uXLFUBZuXKlyfK3335bcXZ2VpYvX64kJiYqjzzyiOLn52cyEtKYMWOUpk2bKnFxccrevXuVu+66S4mMjFTKysqM6wwcOFBp3769snXrVmXr1q1K+/btlfvuu6+uvuZtGTBggLJo0SLl4MGDSkJCgnLvvfcqgYGBSkFBgXGdxl5Pq1atUlavXq0cPXpUOXr0qPLqq68q1tbWysGDBxVFkfq52s6dO5Xg4GAlIiLCOGqZokg9KYqizJgxQwkLC1PS0tKMU0ZGhnF5Q6sjSdS3qEuXLsqYMWNMytq0aaO88sorZoqoblydqPV6veLr66u8/fbbxrLi4mLF1dVV+fTTTxVFUZScnBzF2tpaWbZsmXGdc+fOKWq1Wlm7dq2iKIpy+PBhBVC2b99uXGfbtm0KoBw5cuQOf6vaVzH85KZNmxRFkXq6Hnd3d+Xzzz+X+rlKfn6+0qpVKyUuLs5keFGpJ4MZM2YokZGR11zWEOtIur5vQUlJCXv27KF///4m5f379zeOfNRYJCcnk56eblIXtra29OnTx1gXe/bsobS01GQdf39/2rdvb1xn27ZtuLq60rVrV+M63bp1w9XVtV7WaW5uLlA5hKXUkymdTseyZcsoLCwkJiZG6ucqY8eO5d5776Vfv34m5VJPlY4fP46/vz8hISE8+uijnDp1CmiYdSTv+r4FmZmZ6HQ64zi/FXx8fKoMuNDQVXzfa9XFmTNnjOvY2Njg7u5eZZ2K7dPT0/H29q6yf29v73pXp4qiMGnSJHr27GkcI1rqySAxMZGYmBiKi4txcnJi5cqVtGvXzviHr7HXD8CyZcvYu3cvu3btqrJMfo8Munbtytdff03r1q25cOECb775Jt27d+fQoUMNso4kUd+Gq8fpVRTlmmP3Nga3UhdXr3Ot9etjnY4bN44DBw5ccwjKxl5PoaGhJCQkkJOTw/Llyxk1ahSbNm0yLm/s9ZOamsoLL7zAunXrsLOzu+56jb2eBg0aZPwcHh5OTEwMLVq04KuvvqJbt25Aw6oj6fq+BU2aNEGj0VQ5q8rIyKhyFtfQVdxpeaO68PX1paSkhEuXLt1wnQsXLlTZ/8WLF+tVnY4fP55Vq1axceNGk3GcpZ4MbGxsaNmyJZ06dWL27NlERkby0UcfSf2U27NnDxkZGURHR2NlZYWVlRWbNm3i448/xsrKyvgdGns9Xc3R0ZHw8HCOHz/eIH+XJFHfAhsbG6Kjo4mLizMpj4uLo3v37maKyjxCQkLw9fU1qYuSkhI2bdpkrIvo6Gisra1N1klLS+PgwYPGdWJiYsjNzWXnzp3GdXbs2EFubm69qFNFURg3bhwrVqxgw4YNhISEmCyXero2RVHQarVSP+ViY2NJTEwkISHBOHXq1IkRI0aQkJBA8+bNpZ6uQavVkpSUhJ+fX8P8XarTW9cakIrHs7744gvl8OHDysSJExVHR0fl9OnT5g6t1uXn5yv79u1T9u3bpwDKBx98oOzbt8/4KNrbb7+tuLq6KitWrFASExOV4cOHX/NRiGbNminr169X9u7dq9x9993XfBQiIiJC2bZtm7Jt2zYlPDy83jwu8txzzymurq5KfHy8ySMjRUVFxnUaez1NmTJF2bx5s5KcnKwcOHBAefXVVxW1Wq2sW7dOURSpn+u58q5vRZF6UhRFefHFF5X4+Hjl1KlTyvbt25X77rtPcXZ2Nv79bWh1JIn6Nvzvf/9TgoKCFBsbG6Vjx47GR3Eamo0bNypAlWnUqFGKohgeh5gxY4bi6+ur2NraKr1791YSExNN9nH58mVl3LhxioeHh2Jvb6/cd999SkpKisk6WVlZyogRIxRnZ2fF2dlZGTFihHLp0qU6+pa351r1AyiLFi0yrtPY6+nJJ580/n/x8vJSYmNjjUlaUaR+rufqRC31pBifi7a2tlb8/f2VYcOGKYcOHTIub2h1JKNnCSGEEBZMrlELIYQQFkwStRBCCGHBJFELIYQQFkwStRBCCGHBJFELIYQQFkwStRBCCGHBJFHfBq1Wy8yZM9FqteYOxaJJPd2c1NHNSR3dnNTRzdXHOpLnqG9DXl4erq6u5Obm4uLiYu5wLJbU081JHd2c1NHNSR3dXH2sI2lRCyGEEBZMErUQQghhwRrdeNRlZWXs27cPHx8f1OrbO0/Jz88H4Ny5c+Tl5dVGeA2S1NPNSR3dnNTRzUkd3Zyl1JFer+fChQtERUVhZXXjVNzorlHv2rWLLl26mDsMIYQQgp07d9K5c+cbrtPoWtQVA37v3LkTPz8/M0cjhBCiMUpLS6NLly7GnHQjjS5RV3R3+/n50axZMzNHI4QQojGrziVYuZlMCCGEsGCSqIUQQggLJolaCCGEsGCN7hq1EELciE6no7S01NxhiHrO2toajUZTK/uSRC2EEICiKKSnp5OTk2PuUEQD4ebmhq+vLyqV6rb2I4n6dhTnwrm9YOcCTaPNHY0Q4jZUJGlvb28cHBxu+4+raLwURaGoqIiMjAyA234UWBL17dixADa+Ce0fgoe+MHc0QohbpNPpjEna09PT3OGIBsDe3h6AjIwMvL29b6sbXG4mux1NOxr+Pb/XvHEIIW5LxTVpBwcHM0ciGpKK36fbvedBEvXt8I8y/Jt9Ci5fMm8sQojbJt3dojbV1u+TJOrb4eAB7iGGz+f3mTcWIYQQDZIk6ttV0f19Trq/hRANQ9++fZk4cWK11z99+jQqlYqEhIQ7FhNAfHw8KpWq0d2Zb9ZEPXv2bDp37oyzszPe3t4MHTqUo0eP3nCbih/U1dORI0fqKOqr+Fdcp5YWtRCibl3rb+GV0+jRo29pvytWrOCNN96o9voBAQGkpaXRvn37WzqeuDGz3vW9adMmxo4dS+fOnSkrK2Pq1Kn079+fw4cP4+joeMNtjx49iouLi3Hey8vrTod7bdKiFkKYSVpamvHz999/z/Tp000aOxV3HlcoLS3F2tr6pvv18PCoURwajQZfX98abSOqz6wt6rVr1zJ69GjCwsKIjIxk0aJFpKSksGfPnptu6+3tja+vr3GqrTfA1JhfJKjUkH8e8tPNE4MQolG68m+gq6srKpXKOF9cXIybmxs//PADffv2xc7OjiVLlpCVlcXw4cNp1qwZDg4OhIeHs3TpUpP9Xt31HRwczH/+8x+efPJJnJ2dCQwMZMGCBcblV3d9V/R8/vnnn3Tq1AkHBwe6d+9epcf0zTffxNvbG2dnZ55++mleeeUVOnToUKM6WL58OWFhYdja2hIcHMycOXNMln/yySe0atUKOzs7fHx8eOihh4zLfvrpJ8LDw7G3t8fT05N+/fpRWFhYo+PXBYu6Rp2bmwtU72wuKioKPz8/YmNj2bhx450O7Zp+STjHxBXHKHJtaSiQVrUQDYaiKBSVlJllUhSl1r7Hyy+/zIQJE0hKSmLAgAEUFxcTHR3Nb7/9xsGDB3n22WcZOXIkO3bsuOF+5syZQ6dOndi3bx/PP/88zz333E0vOU6dOpU5c+awe/durKysePLJJ43Lvv32W9566y3eeecd9uzZQ2BgIPPnz6/Rd9uzZw8PP/wwjz76KImJicycOZNp06axePFiAHbv3s2ECROYNWsWR48eZe3atfTu3Rsw9EYMHz6cJ598kqSkJOLj4xk2bFit1n1tsZgXniiKwqRJk+jZs+cNr3P4+fmxYMECoqOj0Wq1fPPNN8TGxhIfH2/8AVxJq9Wi1WqN8/n5+bUW8+ZjmfyccJ6nA0NpzzE4twfaDK61/QshzOdyqY520/8wy7EPzxqAg03t/HmeOHEiw4YNMymbPHmy8fP48eNZu3YtP/74I127dr3ufgYPHszzzz8PGJL/hx9+SHx8PG3atLnuNm+99RZ9+vQB4JVXXuHee++luLgYOzs7/vvf//LUU0/xxBNPADB9+nTWrVtHQUFBtb/bBx98QGxsLNOmTQOgdevWHD58mPfee4/Ro0eTkpKCo6Mj9913H87OzgQFBREVZXisNi0tjbKyMoYNG0ZQUBAA4eHh1T52XbKYFvW4ceM4cOBAlS6Yq4WGhvLMM8/QsWNHYmJi+OSTT7j33nt5//33r7n+7NmzcXV1NU7t2rWrtZijAt0A2F0abCiQF58IISxMp06dTOZ1Oh1vvfUWEREReHp64uTkxLp160hJSbnhfiIiIoyfK7rYK16RWZ1tKl6jWbHN0aNH6dKli8n6V8/fTFJSEj169DAp69GjB8ePH0en03HPPfcQFBRE8+bNGTlyJN9++y1FRUUAREZGEhsbS3h4OP/85z9ZuHAhly5Z5vswLKJFPX78eFatWsXmzZtp1qxZjbfv1q0bS5YsueayKVOmMGnSJOP8uXPnai1ZdwhwA+D3S/6MBsOd34oC8tIEIeo9e2sNh2cNMNuxa8vVN+bOmTOHDz/8kLlz5xIeHo6joyMTJ06kpKTkhvu5+iY0lUqFXq+v9jYVL/+4cpurXwhS025nRVFuuA9nZ2f27t1LfHw869atY/r06cycOZNdu3bh5uZGXFwcW7duZd26dfz3v/9l6tSp7Nixg5CQkBrFcaeZtUWtKArjxo1jxYoVbNiw4ZYrZ9++fdd96bmtrS0uLi7GydnZ+XZCNtHG1xk7azV7i5tSZu8FvhGgzau1/QshzEelUuFgY2WW6U6+Ie2vv/7i/vvv57HHHiMyMpLmzZtz/PjxO3a86wkNDWXnzp0mZbt3767RPtq1a8fff/9tUrZ161Zat25tvMHYysqKfv368e6773LgwAFOnz7Nhg0bAMPPuEePHrz++uvs27cPGxsbVq5ceRvf6s4wa4t67NixfPfdd/zyyy84OzuTnm64a9rV1dX4WMGUKVM4d+4cX3/9NQBz584lODiYsLAwSkpKWLJkCcuXL2f58uV1Hr+VRk1EMzd2Jmez4u4NPNw5sM5jEEKImmjZsiXLly9n69atuLu788EHH5Cenk7btm3rNI7x48fzzDPP0KlTJ7p3787333/PgQMHaN68ebX38eKLL9K5c2feeOMNHnnkEbZt28a8efP45JNPAPjtt984deoUvXv3xt3dnTVr1qDX6wkNDWXHjh38+eef9O/fH29vb3bs2MHFixfrvB6qw6yJuuIOv759+5qUL1q0yPigflpamsm1k5KSEiZPnsy5c+ewt7cnLCyM1atXM3iweW7iigowJOqEs7k83NksIQghRLVNmzaN5ORkBgwYgIODA88++yxDhw41PnVTV0aMGMGpU6eYPHkyxcXFPPzww4wePbpKK/tGOnbsyA8//MD06dN544038PPzY9asWcb84ebmxooVK5g5cybFxcW0atWKpUuXEhYWRlJSEps3b2bu3Lnk5eURFBTEnDlzGDRo0B36xrdOpVjiveh30NmzZwkICCA1NfWWrodfbe3BNMYs2UtbPxd+f6EXaPPBtva614UQd15xcTHJycmEhIRgZ2dn7nAarXvuuQdfX1+++eYbc4dSK270e1WTXGQRN5PVZ1GB7gBcSj+Dfu5Y1IWZMCUV1GZ6AYsQQtQDRUVFfPrppwwYMACNRsPSpUtZv349cXFx5g7N4ljM41n1lY+LHX6udmQorigFF6G0ELJOmjssIYSwaCqVijVr1tCrVy+io6P59ddfWb58Of369TN3aBZHWtS1ICrQjTWJxayMWMBD9/QEe3dzhySEEBbN3t6e9evXmzuMekFa1LUgKsCQmONy/SRJCyGEqFWSqGtBh/I3lO1NybHI98QKIYSovyRR14L2/q5YqVXk5edT8NsU+GoIlGlvvqEQQghxE5Koa4G9jYa2fi5oscYmcRkkb4b0g+YOSwghRAMgibqWGN77rSLVrnwkGRmgQwghRC2QRF1LKkbS2qsrf1+5jE0thBCiFkiiriUVLz75M6+poUBa1EKIeqJv375MnDjROB8cHMzcuXNvuI1KpeLnn3++7WPX1n5uZObMmXTo0OGOHuNOkkRdS4I9HXBzsGZPafkL5S8eNbxOVAgh7pAhQ4Zc9wUh27ZtQ6VSsXdvzRsNu3bt4tlnn73d8ExcL1mmpaVZ5Pu1LYkk6lqiUqnoEOBGJq4U2PkCCqTtN3dYQogG7KmnnmLDhg2cOXOmyrIvv/ySDh060LFjxxrv18vLCwcHh9oI8aZ8fX2xtbWtk2PVV5Koa1HFi09OWrc2FMh1aiHEHXTffffh7e3N4sWLTcqLior4/vvveeqpp8jKymL48OE0a9YMBwcHwsPDWbp06Q33e3XX9/Hjx+nduzd2dna0a9fumu/jfvnll2ndujUODg40b96cadOmUVpaCsDixYt5/fXX2b9/PyqVCpVKZYz56q7vxMRE7r77buzt7fH09OTZZ5+loKDAuHz06NEMHTqU999/Hz8/Pzw9PRk7dqzxWNWh1+uZNWsWzZo1w9bWlg4dOrB27Vrj8pKSEsaNG4efnx92dnYEBwcze/Zs4/KZM2cSGBiIra0t/v7+TJgwodrHvhXyCtFaVPHikx3FQUSCXKcWoiEoKaz5Nhpb0JT/edWVgU4LKjVY2998vzaO1T6MlZUVjz/+OIsXL2b69OmoVCoAfvzxR0pKShgxYgRFRUVER0fz8ssv4+LiwurVqxk5ciTNmzena9euNz2GXq9n2LBhNGnShO3bt5OXl2dyPbuCs7Mzixcvxt/fn8TERJ555hmcnZ156aWXeOSRRzh48CBr1641vjbU1dW1yj6KiooYOHAg3bp1Y9euXWRkZPD0008zbtw4k5ORjRs34ufnx8aNGzlx4gSPPPIIHTp04JlnnqlWvX300UfMmTOHzz77jKioKL788kv+8Y9/cOjQIVq1asXHH3/MqlWr+OGHHwgMDCQ1NZXU1FQAfvrpJz788EOWLVtGWFgY6enp7N9/Z3tPJVHXog7N3ACILwzgWRvg3B6zxiOEqAX/8a/5Nv9cDGEPGD4f+RV+HA1BPeGJ1ZXrzA2Hoqyq286s2bjQTz75JO+99x7x8fHcddddgKHbe9iwYbi7u+Pu7s7kyZON648fP561a9fy448/VitRr1+/nqSkJE6fPm0cjvE///lPlevKr732mvFzcHAwL774It9//z0vvfQS9vb2ODk5YWVlha+v73WP9e2333L58mW+/vprHB0NJyzz5s1jyJAhvPPOO/j4+ADg7u7OvHnz0Gg0tGnThnvvvZc///yz2on6/fff5+WXX+bRRx8F4J133mHjxo3MnTuX//3vf6SkpNCqVSt69uyJSqUiKCjIuG1KSgq+vr7069cPa2trAgMD6dKlS7WOe6uk67sWuTpY09zLkYP68ke0clKgMNO8QQkhGrQ2bdrQvXt3vvzySwBOnjzJX3/9xZNPPgmATqfjrbfeIiIiAk9PT5ycnFi3bh0pKSnV2n9SUhKBgYEmYybHxMRUWe+nn36iZ8+e+Pr64uTkxLRp06p9jCuPFRkZaUzSAD169ECv13P06FFjWVhYGBpN5VDCfn5+ZGRkVOsYeXl5nD9/nh49epiU9+jRg6SkJMDQvZ6QkEBoaCgTJkxg3bp1xvX++c9/cvnyZZo3b84zzzzDypUrKSsrq9H3rClpUdeyqAB3ll8sJNsuEI/iFDi/D1rdY+6whBC36tXzNd9Gc8XNUW2GGPahuqpdNDHx9uK6wlNPPcW4ceP43//+x6JFiwgKCiI2NhaAOXPm8OGHHzJ37lzCw8NxdHRk4sSJlJSUVGvf1xq/oKKLvcL27dt59NFHef311xkwYACurq4sW7aMOXPm1Oh7KIpSZd/XOqa1tXWVZXq9vkbHuvo4Vx67Y8eOJCcn8/vvv7N+/Xoefvhh+vXrx08//URAQABHjx4lLi6O9evX8/zzz/Pee++xadOmKnHVFmlR17KKF58kqVsaCuSGMiHqNxvHmk+aK9pAGitD2ZXXp2+031vw8MMPo9Fo+O677/jqq6944oknjEnnr7/+4v777+exxx4jMjKS5s2bc/z48Wrvu127dqSkpHD+fOUJy7Zt20zW2bJlC0FBQUydOpVOnTrRqlWrKnei29jYoNPpbnqshIQECgsrr99v2bIFtVpN69atqx3zjbi4uODv78/ff/9tUr5161batm1rst4jjzzCwoUL+f7771m+fDnZ2dmAYYjOf/zjH3z88cfEx8ezbds2EhNr78TratKirmWGV4nCkqKuxPTri7plrHkDEkI0eE5OTjzyyCO8+uqr5ObmMnr0aOOyli1bsnz5crZu3Yq7uzsffPAB6enpJknpRvr160doaCiPP/44c+bMIS8vj6lTp5qs07JlS1JSUli2bBmdO3dm9erVrFy50mSd4OBgkpOTSUhIoFmzZjg7O1d5LGvEiBHMmDGDUaNGMXPmTC5evMj48eMZOXKk8fp0bfj3v//NjBkzaNGiBR06dGDRokUkJCTw7bffAvDhhx/i5+dHhw4dUKvV/Pjjj/j6+uLm5sbixYvR6XR07doVBwcHvvnmG+zt7U2uY9c2aVHXsja+zthZq/m9OJxTrZ8E3/bmDkkI0Qg89dRTXLp0iX79+hEYGGgsnzZtGh07dmTAgAH07dsXX19fhg4dWu39qtVqVq5ciVarpUuXLjz99NO89dZbJuvcf//9/Otf/2LcuHF06NCBrVu3Mm3aNJN1HnzwQQYOHMhdd92Fl5fXNR8Rc3Bw4I8//iA7O5vOnTvz0EMPERsby7x582pWGTcxYcIEXnzxRV588UXCw8NZu3Ytq1atolWrVoDhxOedd96hU6dOdO7cmdOnT7NmzRrUajVubm4sXLiQHj16EBERwZ9//smvv/6Kp6dnrcZ4JZXSyAZQPnv2LAEBAaSmpprcHFGbHv5sGzuTs3n3oQge7hRwR44hhKg9xcXFJCcnExISgp2dnbnDEQ3EjX6vapKLpEV9B0SVd3+fPpkEB36E9Dt37UIIIUTDJon6Dqi4oSz85EJY8TQcXG7egIQQQtRbkqjvAONIWoXN0flHg0tTM0ckhBCivpJEfQf4uNjh52rHT7re7Or3I3Sp3ttyhBBCiKtJor5DKrq/96XkmDUOIYQQ9Zsk6jukYiStfSmXoKQICq/xTl8hhEWp6duthLiR2vp9khee3CEVI2lFnv4SZfZSVF3+Hwx627xBCSGuycbGBrVazfnz5/Hy8sLGxua6r7IU4mYURaGkpISLFy+iVquxsbG5rf1Jor5D2vu7YqVWcaLYBZWNXoa8FMKCqdVqQkJCSEtLM3lVphC3w8HBgcDAQNTq2+u8Nmuinj17NitWrODIkSPY29vTvXt33nnnHUJDQ2+43aZNm5g0aRKHDh3C39+fl156iTFjxtRR1NVjb6OhrZ8L+8+3MBSkHTCMS6uRcyMhLJGNjQ2BgYGUlZXd9J3UQtyMRqPBysqqVnpmzJo1Nm3axNixY+ncuTNlZWVMnTqV/v37c/jwYZNhzq6UnJzM4MGDeeaZZ1iyZAlbtmzh+eefx8vLiwcffLCOv8GNdQhwY8k5X4o1jtiVFcLFJPANN3dYQojrUKlUWFtb37FRkIS4FWZN1GvXrjWZX7RoEd7e3uzZs4fevXtfc5tPP/2UwMBA5s6dC0Dbtm3ZvXs377//vsUl6qhAN77ZruaYpiURuv2GkbQkUQshhKgBi7rrOzc3FwAPD4/rrrNt2zb69+9vUjZgwAB2795NaWnpHY2vpipefLK9uHxUFblOLYQQooYs5oKpoihMmjSJnj170r799UecSk9PrzLcmY+PD2VlZWRmZuLn52eyTKvVotVqjfP5+fm1G/gNBHs64OZgzd7i5mCDjE0thBCixiymRT1u3DgOHDhwzaHPrnb1xfmKAcCuddF+9uzZuLq6Gqd27drVTsDVoFKp6BDgxgF9c0NBxmEoLa6z4wshhKj/LCJRjx8/nlWrVrFx48abDvfl6+tLenq6SVlGRgZWVlbXHA90ypQp5ObmGqfDhw/Xauw3ExXgznk8yde4g75MRtISQghRI2ZN1IqiMG7cOFasWMGGDRsICQm56TYxMTHExcWZlK1bt45OnTpd805NW1tbXFxcjJOzs3OtxV8dhhefqDhI+WNacp1aCCFEDZg1UY8dO5YlS5bw3Xff4ezsTHp6Ounp6Vy+fNm4zpQpU3j88ceN82PGjOHMmTNMmjSJpKQkvvzyS7744gsmT55sjq9wUx2auQFX3FB2bo/5ghFCCFHvmDVRz58/n9zcXPr27Yufn59x+v77743rpKWlkZKSYpwPCQlhzZo1xMfH06FDB9544w0+/vhji3s0q4KrgzUtvBzZr5Rfp5YbyoQQQtSAWe/6rrgJ7EYWL15cpaxPnz7s3Vt/El6HAHc2Xizv+s47bxikw8bBvEEJIYSoFyziZrKGLirQjWxceNl3IbySIklaCCFEtUmirgMVY1OvSXNFr9KYNxghhBD1iiTqOhDq44y9tYZ8bRmnMgvMHY4QQoh6RBJ1HbDSqAlv5ooXl9CsGgtf32/ukIQQQtQTkqjrSFSgG0XYEXR2FZyKh4IMc4ckhBCiHpBEXUeiAtwoxJ4F9k/D8O/BxsncIQkhhKgHJFHXkYqRtN7NuYvC4H5y57cQQohqkURdR3xc7PB3tUOvwIGzueYORwghRD0hiboOdQh0w5oyLu37BTa9B9V44YsQQojGTRJ1HYoKcEeNngEHJ8PGNyEn5eYbCSGEaNQkUdehqEA3tNhwjPIBOmQkLSGEEDchiboOtW/qipVaxd6y8uE8ZYAOIYQQNyGJug7ZWWto6+dCglIxNvU+8wYkhBDC4kmirmNRgW4c0JcPeXk+AfR6s8YjhBDCskmirmMdAtw4oTSlGFsoyYes4+YOSQghhAWTRF3HogLd0aHhoBJsKJDr1EIIIW5AEnUdC/Z0wM3BmgRdRfe3JGohhBDXd0uJOjU1lbNnzxrnd+7cycSJE1mwYEGtBdZQqVQqOgS4cUBffkOZtKiFEELcwC0l6v/7v/9j48aNAKSnp3PPPfewc+dOXn31VWbNmlWrATZEUQHu7FfKW9TpiVBWYt6AhBBCWKxbStQHDx6kS5cuAPzwww+0b9+erVu38t1337F48eLajK9Bigp044ziQx5OoNNCxmFzhySEEMJC3VKiLi0txdbWFoD169fzj3/8A4A2bdqQlpZWe9E1UJEBboCKBF3Fi0/2mDMcIYQQFuyWEnVYWBiffvopf/31F3FxcQwcOBCA8+fP4+npWasBNkSu9ta08HLkL304mf53gYu/uUMSQghhoW4pUb/zzjt89tln9O3bl+HDhxMZGQnAqlWrjF3i4saiAt1ZqLuPr4PfgdBB5g5HCCGEhbK6lY369u1LZmYmeXl5uLu7G8ufffZZHBwcai24hqxDgBs/7TnLvtQcc4cihBDCgt1Si/ry5ctotVpjkj5z5gxz587l6NGjeHt712qADVVUoBsACSmX0F9KhcIs8wYkhBDCIt1Sor7//vv5+uuvAcjJyaFr167MmTOHoUOHMn/+/FoNsKEK9XHG3lrDTP1/UX/UHg4sM3dIQgghLNAtJeq9e/fSq1cvAH766Sd8fHw4c+YMX3/9NR9//HGtBthQWWnUhDdzJVnvh16lgYIL5g5JCCGEBbqlRF1UVISzszMA69atY9iwYajVarp168aZM2dqNcCGLCrQja90A5gZ9gfcIy+KEUIIUdUtJeqWLVvy888/k5qayh9//EH//v0ByMjIwMXFpVYDbMiiAtzJx4Fd54rNHYoQQggLdUuJevr06UyePJng4GC6dOlCTEwMYGhdR0VFVXs/mzdvZsiQIfj7+6NSqfj5559vuH58fDwqlarKdOTIkVv5GmZXcUPZ0fQ8CrVl5g1GCCGERbqlRP3QQw+RkpLC7t27+eOPP4zlsbGxfPjhh9XeT2FhIZGRkcybN69Gxz969ChpaWnGqVWrVjXa3lL4uNjh72rHMPUm9Avuhi1yfV8IIYSpW3qOGsDX1xdfX1/Onj2LSqWiadOmNX7ZyaBBgxg0qOYv+/D29sbNza3G21miqEB3XA8X4Jy1H1KaQY8J5g5JCCGEBbmlFrVer2fWrFm4uroSFBREYGAgbm5uvPHGG+j1+tqOsYqoqCj8/PyIjY01juJVX5kMeSljUwshhLjKLbWop06dyhdffMHbb79Njx49UBSFLVu2MHPmTIqLi3nrrbdqO04A/Pz8WLBgAdHR0Wi1Wr755htiY2OJj4+nd+/e19xGq9Wi1WqN8/n5+XcktlsVFejGB0owOtRo8tMgLw1c/MwdlhBCCAtxS4n6q6++4vPPPzeOmgUQGRlJ06ZNef755+9Yog4NDSU0NNQ4HxMTQ2pqKu+///51E/Xs2bN5/fXX70g8taF9U1dK1fYc1zeljTrV0Kp2udfcYQkhhLAQt9T1nZ2dTZs2baqUt2nThuzs7NsOqia6devG8ePHr7t8ypQp5ObmGqfDhy1r7Gc7aw1t/Vw4oG9uKDgn3d9CCCEq3VKivt6d2vPmzSMiIuK2g6qJffv24ed3/a5iW1tbXFxcjFPFi1osSVSgGweU8kQt16mFEEJc4Za6vt99913uvfde1q9fT0xMDCqViq1bt5KamsqaNWuqvZ+CggJOnDhhnE9OTiYhIQEPDw8CAwOZMmUK586dM75XfO7cuQQHBxMWFkZJSQlLlixh+fLlLF++/Fa+hsXoEODGou0VN5TtA0UBlcq8QQkhhLAIt9Si7tOnD8eOHeOBBx4gJyeH7Oxshg0bxqFDh1i0aFG197N7926ioqKML0mZNGkSUVFRTJ8+HYC0tDRSUlKM65eUlDB58mQiIiLo1asXf//9N6tXr2bYsGG38jUsRlSgO0eUQEoUK7h8CS4lmzskIYQQFkKlKIpSWzvbv38/HTt2RKfT1dYua93Zs2cJCAggNTWVZs2amTscABRFIeqNOBaXvUwH9Sl48AsIf8jcYQkhhLhDapKLbqlFLWqXSqW66nnqfeYNSAghhMWQRG0hogLcK28oO7fHvMEIIYSwGJKoLURUoBv7K1rUaftBJ4N0CCGEqOFd3ze7aSsnJ+d2YmnUIgPcOKn4M610NJMfG46r3PUthBCCGiZqV1fXmy5//PHHbyugxsrV3poQL2e+udifu8pCuFutMXdIQgghLECNEnVNHr0SNRcV6M7Ji4XsS8nh7jY+5g5HCCGEBZBr1BakQ4AbLhTgmrQUNr9v7nCEEEJYAEnUFiQq0A0XVRFPX/oQJf5tKNPefCMhhBANmiRqCxLq40yWlS/rdNFcingaSi+bOyQhhBBmJonaglhp1IQ3c+PZ0hdZ32ws2LuZOyQhhBBmJonawkQFugGwLyXHrHEIIYSwDJKoLUxUgDsAx0+nQsp2M0cjhBDC3CRRW5ioQDc8yOOnvOEoXw4Ebb65QxJCCGFGkqgtjI+LHXau3pxXPFChGF4nKoQQotGSRG2BogLdK0fSOrfXvMEIIYQwK0nUFsgw5GX5SFrnJVELIURjJonaAkUFupGgGFrUirSohRCiUZNEbYHaN3UlCUOLWpVzBgqzzByREEIIc5FEbYHsrDU08/PjpN7PUHB+n3kDEkIIYTaSqC1UVKAbBxS5Ti2EEI2dJGoLFRV4xQ1lcp1aCCEaLUnUFqpDgDv7yx/RUs7vBUUxc0RCCCHMQRK1hQr2dOC8XUvKFDWqgguQd97cIQkhhDADSdQWSqVS0TbQh2NKgKFArlMLIUSjJInaghm6v5tTpHaComxzhyOEEMIMJFFbsKhAN94oG8kgu28gepS5wxFCCGEGkqgtWGSAG0XYcSb7MlkFWnOHI4QQwgwkUVswV3trWng5ArD/bI7c+S2EEI2QJGoLFxXozr+sfiR6ZR848IO5wxFCCFHHzJqoN2/ezJAhQ/D390elUvHzzz/fdJtNmzYRHR2NnZ0dzZs359NPP73zgZpRVKAbLhThqk2TV4kKIUQjZNZEXVhYSGRkJPPmzavW+snJyQwePJhevXqxb98+Xn31VSZMmMDy5cvvcKTm0yHAjaW6u3lamYa+z8vmDkcIIUQdszLnwQcNGsSgQYOqvf6nn35KYGAgc+fOBaBt27bs3r2b999/nwcffPAORWleoT7OpFoFc0yr42S+Fa0czB2REEKIulSvrlFv27aN/v37m5QNGDCA3bt3U1paes1ttFoteXl5xik/P78uQq01Vho1Ec1cAdiXkmPeYIQQQtS5epWo09PT8fHxMSnz8fGhrKyMzMzMa24ze/ZsXF1djVO7du3qItRa1SHQja6qJHx3vAXH/jB3OEIIIepQvUrUYHi15pWU8keWri6vMGXKFHJzc43T4cOH73iMtS0qwJ2+mgR6Zy6FI6vNHY4QQog6ZNZr1DXl6+tLenq6SVlGRgZWVlZ4enpecxtbW1tsbW2N83l5eXc0xjshKtCNn8tH0tKd24vGzPEIIYSoO/WqRR0TE0NcXJxJ2bp16+jUqRPW1tZmiurO83Gx44JTWwDUGYeh9LKZIxJCCFFXzJqoCwoKSEhIICEhATA8fpWQkEBKSgpg6LZ+/PHHjeuPGTOGM2fOMGnSJJKSkvjyyy/54osvmDx5sjnCr1P+ga24qLigUnSQnmjucIQQQtQRsybq3bt3ExUVRVRUFACTJk0iKiqK6dOnA5CWlmZM2gAhISGsWbOG+Ph4OnTowBtvvMHHH3/cYB/NulJUkDsHyru/OSdDXgohRGNh1mvUffv2Nd4Mdi2LFy+uUtanTx/27m18iapDgBub9S2I1exDOb+Ha986J4QQoqGpV9eoG7P2TV05iKFFXZa6x8zRCCGEqCuSqOsJO2sNWp9IAKwvnYTiXDNHJIQQoi5Ioq5HWgQFkar3MsycTzBrLEIIIeqGJOp6JCrQjf1Kc8PM+cZ3nV4IIRojSdT1SFSAOwf0hkStPyuJWgghGgNJ1PVIkKcDp2xCAShL3W3maIQQQtQFSdT1iEqlwrpZFL/purHf/1HQ680dkhBCiDtMEnU90za4KeNKJ/Ct5h+glh+fEEI0dPKXvp7pEOAGwL7UHLPGIYRofLRlOraeyORyic7coTQq9Wr0LAGRAW6o0KPOPknuYT2u7WLNHZIQohHYfOwiM1YdIjmzkBZejvxvREfa+LqYO6xGQVrU9YyrvTWDPdPZaPsi9r88BTd4BasQQtyu8zmXeW7JHh7/cifJmYUAnLxYyP3ztrB0Z8oNXwMtaock6nrIOTCSfMWeTOumoK1/42sLISxfSZme+fEniZ2zid8PpqNRq3iyRwib/t2XvqFeaMv0TFmRyIRlCeQXl5o73AZNur7rofBgHyL3LaR7gDdL7FzNHU6jkl1Ywh+H0ll9II0TGQUEeNjTvIkTLbwdad7EieZejgR6OGClkXNgUX9tOZHJ9F8OcvKioQXdOdidWfe3p62foav7y1GdWfjXKd774yi/7j/PgbM5/O//OtK+qfw9uhMkUddDHQLc0KNmf2oOer2CWi1jad1JuUWl/HEond8S09hyIhOdvrKrLz2vmF2nL5msb61REejhQHMvJ1p4GZJ3Cy9HWng54eZgU9fhC1Ft6bnFvLn6ML8dSAOgiZMNUwa1ZVjHpqhUlX9n1GoV/69PCzoFezBh6T7OZBUx7JOtvDq4DaO6B5usK26fJOp6KNTHGXtrDfnaMk6mZ9PK39PcITU4ecWlxB26wG8HzvP3iUxKdZXJOczfhXsj/OgS7MG5nMucvFjIqYsFnLpYyKnMAopL9Zy8WMjJi4XEccFkvx6ONjRv4mhM4IZk7kiAhwPW0goXZlKq07NoSzIfrT9OYYkOtQpGdgtiUv9QXO2tr7tddJA7ayb04t8/7Wfd4QvM/PUwW09m8d5Dkbg6XH87UTOSqOshK42aPn5lTEx/haAvc2H412DjBLZOYONo+GzjBFbSequJ/OJS/kzK4LcD59l8LJMSXeULZdr4OnNfhB+Dw/1o7uVkLO901T70eoW0vGJOXSzgZEYBpzILOXWxkJMXC0jLLSa7sITswhJ2nzFthVupVQR6Ohi70Vs0qWiJO+HuKD9HcedsO5nF9F8OcjyjAICOgW7Mur99tbuxXR2s+WxkNF9tPc1/1hxh3eELHPr4L/77f1F0DHS/k6E3Giqlkd2yd/bsWQICAkhNTaVZs2bmDueWvb0mkQk7YnFQaa+/ksamMmnbOoFnS3jkm8rlf38Ily9Bx1HgaRjrmktn4OLRqknf1gmsHaA6XVp6HZReBitb0JSfVRdkQOYxQ3lpEZQUGf4tvVxZVnpVmUptGu+Po+HUJhgyF9rdbyg7uQF+GFUeo/MVkxPYulTOG5eXl7WMBY01hdoy4g+eZs2hDOKO5VJSVpmcW3k7cV+EP/dG+NLS27laP5cbKSopMyZtQ+u7kJMZBSRnFnK59PrPpbo7WBtb3s29nAwtcm8nguRauLgNGXnF/GdNEj8nnAcMvT2vDGrDQx2b3fLltMSzuYxbupczWUVYqVX8e0Aoz/RqLpfnrqEmuUha1PVUh0Av3tzyGI/ZbaGdpwZK8qGkELQFoCtP3roSuJxtmAC46j/Lvm8h6zi0GlCZqI/9Ab//+zpHVV2RvB0NyVDRg4MnPP5L5WoL+kL6ARixHFr1q9zvqnE1+5JW9qbzJUWG76LNrywrzjPc+a7Ng3yq7ff7D/Dr4Uw2HMlgNv/lf5otvKGMYGOTh7kvwo9hzXIJ3j4dLjjDpitPAlzKTwKcDScuGmtQaUBtBWoNhPSp7MnIToaiLHBpCi5+ONhY0d7HjvZ2mRBoDWpPUPugR01GYRnJWcWcytaSnHWZ45nFnLxYxNm8Ei4VlbLnzCX2XNUKd7K1IqaFJ71be9G7VROCPB1rVr+WRK8HfSnoSkFfZph0pYYyfRnoygyfnf3AwcOwTVE2pCcafhebXdG3cTzO8Pug14OiK99f+b+K/qp5nWG9kF4Q2M2wfe5Z2PaJ4Wd815TK/ca/A9knDduprcDO1TDZulR+tnMFOxewc6uc11hWF3CZTs9X287wYdwxCrRlqFQwomsgk/uH3vY9FOHNXPltfE+mrEjktwNpzP79CNtOZTHnn5F4OtnW0je4Ab3O8MiqWlPZqNCVGv4WKvryx1mVys9Xz1d8VqnB2bdyv3lpUHYZnHwMv291TBJ1PRUV6MYYXSzLimIZ2NwXFztrXOytcbGzwtUWPKxKcbcqxdWqGGeVFmd1MQ529tgoSuWNHtGjDL+AbgGVO7Z3A79IQ8IvKYSSAsMEgHLVfDknX9N5awfDv6VFlWWOTaBJa7C2Nyw3/nvFZxuHq5Zf9R9i0Ntwzyxw8assa3UPjN9bnqzzy6cC0/mSAnSX88jMyiTnUhZFRYU89/1B4y68HEtBB0/dHcFrd/cx1M/JDZCyrcY/F15KBqvyRLJlLuxZDHdNhT4vGcoyj8OnPUw2UQO+5VPM1fuzA0WlYUPsryQWe3HyYiGdUr7kvqKfWaq7i/cPP0Lc4Qt4ksuv9jOxtbbCzsYaOxsrNGpN+R8steGPlkp9xVRefu/74BtuOFbSr7DrC0PS6vWioUyvgx8ev2rb8qkioZokVZ3hc7+ZEFT+bY6shj+mGhLhA59Wfrf3WkFxTmUCrY5//Bc6Pm74fG4vfPsg+EbAmL8q11kzGS6drt7+KqinVybqwkzY/j9w9jdN1Cfi4Oyumu236xgY9E75frNg6SNg7w7/90NlIkn6DQouXJXsrzgBsLavXk9WNexMzmbGzwc4eSEHK3R0b+rI1IEtCfNxgJJ00NuBk7dhZb3eMJyurhSadQZNebo4nwCXkg0nT7qSyhOs8t8BZ10p//Ur5TldFtuOp6M6WcaXHzal14hX6da8/H6alWMMJ9n3fVCZEHd9bmg8VPwuXbFPk88Vvy+KAj5hpj/7eZ0g+xQ8+Uflz3PnQvjjip9jdTj5wuSjlfM/PA5nd8IjS6DtkBrX++2SRF1P+bjY0dLbiRMZBaxJTK/mVqXYaNbiYm+Fi501zvYdcbGzwmVNJi52ubjaW+Ni3xGXyG+MSd/F3hpXOw0umlJcNFpsdZfLk3V5612tNvxBudKIH0BtDVZ2lWWhgwzT7fBoXrXMxrGyN+Aq2jIdm49l8tuB86w/fIHCK1572Mzdnvsi/Lkvwo8w3wFQWoi/xqbyD6JPe/jnV8ZEb0j6V50MlBSWt8iuaJ1d2Xqydwe3QMO/V7J1vaI1V9664/pXoFSKjti2vsRWfM/1nvB3Ho9GeqJqEsrmYxc5e+YS/soFKMEwVVdJYeXnnBQ4tdFwUlVBr4Mjv9Vgh+WKMq84RpHhD/uVJ4Rg6PnR3SBYlcZQn2orw6SxNlzOqWDrDF5twSPEdLumncA1wHAyUdHTobYynTf2gpSX+UZUbu/kAz0mGpLklbo8a7jkotIYEkZFb05xbvl05edcQy/Xlf83LmcbEr2dq2ni3fW5od6vR219RUu9PIG3ux86P2VYXpgFS4YBCvy/zZXb/TIWjq4FfSmKrpSysjKi9aX8rlKg4r9mFvDtFcdq/yA89KXhs6KDz8vffPjy6crf491fwt6vrh8vhr67MCBMDahhS0kY/7dwOxP7tWbsXS3RHP3dcJLWb2Zlos5PN5wY1IT+6ktG5fV65RXdap/kqMrXVRl+R65k42DoSVRprrnlnSbXqOux9Nxitp3KJO9yGXmXS8krLjV8Lq78nGssL0VfCz9pWyu1SRJ3d7DB3cEGTyfDvx6O1ng42uLhaFjm6WiLs51VnV2jKinT8/eJi/x2II24QxfI15YZl/m72nFvhB/3RfgT0czVsh4hMXbTXtkle8W8o1dli6bgIhReNPzhLO9dKCgq4vCev9mfms2B1Euk5xShUelRoaBGj4uthvb+zoT7OxHm54yng5WhVRLUo7Ir+eJRQ2vJLQCCupfHpTP8Ua5oweh15Z/1lQnQmEytDTGqrQ0tsIqej8JMyDpp6K3xCq38zjkp5cmzfPuKbSsSc30fdKbiZ2dV3uVbnAfJmw1JPuyByvU2vQtp+02TfHGu4STgej0NnZ+Ge+cYPhdchPdbGj7PyKlMTD88Dod/uebmVVScFLW7H4YtMJQpCnwUafhZPL2+8vdk63/h6O/lPzObyp//dT6XomHFGTtePhUJQPcWnnza7hAutmoIG1p5AnDxmKE1rLEu37b8xKzi98L4ufykC5VhvStPLC9fMsRt61x50lzR9V2xTUXvEhW9TKpa67GoiZrkIknUjYSiKBSW6IwJPbeolLziayT4y6VXJPfKsnxt2S2/rVSjVuHuYI2HY0Uyr5xMk3zlZGdd/TPXUp2eLScyWX0gjT8OpZNXXJmcfV3sGBzux32RfnRo5tZobmpJzS5i8/GL/HUsky0nM8m/ok4AWno70buVF71aN6FbiCf2NuZpKYgbUMovNV2rxe4RAgFdDOuVlcCpeEMSa36XMekkHjzAJ+v2c/RiMWVoaOnjxqRBYbRv1uSK5FeeWOsgUS3fc5ZpvxykqERHEycbPnykA71aed3x41oqSdQ30FgT9e3S6xUKSsrKE3xlaz33cglZhSVcKiwhu7CU7EIt2UWl5fMlFGjLbr7za3Cw0dwkqVujVqnYcCSDtYfSySmqfIWhl7Mt94b7cW+EH9GB7o0mOV9PmU7P/rM5bDqWyV/HLxpelHPF/3objZrOIe70auVF71ZetPVztqzeBlEjmQVa3vn9CD/uOQsYxgf494BQhncJRGPm/wsnMgoY991ejqTno1LB831b8K9+rRvl0wuSqG9AEnXd0pbpyCkqJaughEtFJcbniI1TUYkxqWcXGta58uUi1dXEyYZB7Q3JuXOwh9n/IFmy3KJStpw0JO3NxzI5l3PZZHkTJ1t6t2pCr9ZN6NnSCy/nOrhbV9w2nV7hu50pvLf2iLFX6eFOzXh5YJu6ueO6mopLdbzx22G+3ZECQKcgdz4eHoW/m/1NtjS/Mp2eczmXa+UJC0nUNyCJ2rIpikK+tswkeVck8Ktb7gXaMqKDPBgS4UeXEI9GeVZ+uxRF4VRmIZuPXeSv45lsO5lV5Znudn4u9GrdhD6tvIgOdsfW6ta7yfV6hcKSMopKdBRqyyjU6srnyyjQ6ijSllFYsaykjCLtFZ9LdBRoDWU6RSGiqStdm3vQNcSTIE+HRt0LsC/lEtN+OcjBc4ZBetr5ufDG0PZEB1nuC0d+O3CeKcsTydeW4eZgzfsPRdKvnY+5wzKhKApHL+Sz5UQW205msuNUNjZWanZN7XfbPXWSqG9AErUQ16ct07HnzCU2l3eTHzpvOjqbvbWGbs096NnKC2c7K5PEakykJeUJuHyZYd5QdqMXu9wOHxdbuoZ4GhN3Cy/HRpG4swtLeO+PIyzblYqigLOdFZP7hzKia2C9OHE9k1XIuO/2kXguF4Cneobw8sA22FiZJ3ZFUUjJLmLrySy2nDCcuGYVmj6Z4GJnxe8Te9P0NnsAJFHfgCRqIaovs0DL38czDTemHc/kYv4N3oRXA2oVONpa4WRrhYONBkdbKxxtrHC01eBgY1U+X15eXnbluiU6PXtOX2JHchYJqTlVLpc0cbKla3MPuoV40LW5J628nRpU4tbrFZbtSuXdP44Y7894sGMzXhnUpt5dqtCW6Xjn96N8uSUZgMhmrvx3eEcCPR3q5PgZecXGxLz1ZFaVS0H21ho6h3jQo4Un3Vs0oZ2/S61cWpNEfQOSqIW4NYqicCQ9n83HLrIzORu9ouBwZUK1scLBVlOeUE0TrXF5eZmtlbrWEmdxqY69KZfYcSqbHclZ7E3JMXkVLBhej9kl2MPY4m7j61wvbzLMLy7l0Pk8Zq9JYv9ZQyu0ja8zs+5vT5cQDzNHd3viDl9g8o/7yb1cirOtFe88FMHgcL+bb1hDuUWlbDtl6MrecjKLExmmL3Cy1qiICnAnpoUnPVo2oUOA2x1p4UuivgFJ1EI0bMWlOvan5rAj2ZC495y5RHGpaeJ2tbemc7AH3coTd221km5XqU5PWk4xKdlFpGQXkXrJ8O/Z8vlLVzzd4GRrxaR7WvN4TFC96OaujnM5l5mwdJ/xdbmPdQvktXvb1ehxzasVlZSx6/Qltp7MZOuJLA6ez63yPpT2/q50b+FJ95ZN6BzsjoPNnX8XWL1K1J988gnvvfceaWlphIWFMXfuXHr16nXNdePj47nrrruqlCclJdGmTZtqHU8StRCNS0mZnsRzOWw/lc2O5Gz2nM42eUsdgLOtFZ2C3ena3JNuzT1p7+9yR5KfoihkFZaQWp54z166TEpWZVI+n3P5pi8mcnew5u42Prw8MBRvF7sbr1wPler0fBB3jPnxJwFo6+fCvP+LosUVo9bdSEmZ4XHEiq7sfSmXqlwaaeHlSI+WTejeogndmnuYZZz4epOov//+e0aOHMknn3xCjx49+Oyzz/j88885fPgwgYGBVdavSNRHjx7FxaXy1XxeXl5oNNU745JELUTjVqbTc/B8HjtOZbEjOZtdydkmb7ADcLTREB3sQdcQQ6s7vGn1uz8vl+g4W94STskuIjX7cnlSNswXldz4hjobKzUB7vYEejgQ4OFg/DfA3YEAD3uc7SxrkI87ZdOxi0z6PoGswhIcbDS89UB7Hoiq+jdbr1c4nJZnTMy7TmdXqeOmbvblLWbDdWYfCzjBqTeJumvXrnTs2JH58+cby9q2bcvQoUOZPXt2lfUrEvWlS5dwc3O7pWNKohZCXEmnV0hKy2P7qSy2n8pm1+lsci+XmqxjZ60mOsjdcGd5iAdN3e0NreEruqVTy+erc8Odr4sdgR4ONPMwJOQrk7KXk229vH5+J1zIK2bisgS2ncoCDM+Fz/xHGOdzig3XmE9ksT05y+SFRwCejjbElN/81aOlJ4Eelvf4Xr0Y5rKkpIQ9e/bwyiuvmJT379+frVu33nDbqKgoiouLadeuHa+99to1u8MraLVatNrK/zj5+TUYC1EI0eBp1CraN3WlfVNXnu7VHL3ecNPcjuQsdpzKZufpbLILS9hyIostJ7KqtU9nW6srWsP25UnZMN/Uzf62rrk2Jj4udix5uivzNpzgoz+P8cPus/yccL7KzYJOtlZ0DfGge8smdG/hSahP/bxZ8HrMlqgzMzPR6XT4+Jg+4O7j40N6+rVHg/Lz82PBggVER0ej1Wr55ptviI2NJT4+nt69e19zm9mzZ/P666/XevxCiIZJrVbRzt+Fdv4uPNEjBL1e4cTFAnacymJ7cjY7TmWTU1RC0/Lu6Wbupgk50MMBV3tri2vB1VcatYoX+rWiS4gHLyzbR0a+FhsrNZ2C3OnRsgkxLTyJaOraYG6ouxazdX2fP3+epk2bsnXrVmJiKkfhfeutt/jmm284cuRItfYzZMgQVCoVq1atuubyq1vU586do127dtL1LYS4JYqioCg0qBZbfVGoLePUxUJa+TjV+16JmnR9m+0UpEmTJmg0miqt54yMjCqt7Bvp1q0bx48fv+5yW1tbXFxcjJOzs/MtxyyEECqVSpK0mTjaWhHezLXeJ+maMluitrGxITo6mri4OJPyuLg4unfvXu397Nu3Dz+/2n8oXgghhLAEZrtGDTBp0iRGjhxJp06diImJYcGCBaSkpDBmzBgApkyZwrlz5/j6668BmDt3LsHBwYSFhVFSUsKSJUtYvnw5y5cvN+fXEEIIIe4YsybqRx55hKysLGbNmkVaWhrt27dnzZo1BAUFAZCWlkZKSopx/ZKSEiZPnsy5c+ewt7cnLCyM1atXM3jwYHN9BSGEEOKOMvubyeqaPEcthBDC3OrFzWRCCCGEuDmzdn2bg15veFA+LS3NzJEIIYRorCpyUEVOupFGl6gvXLgAQJcuXcwciRBCiMbuwoUL1xzb4kqN7hp1WVkZ+/btw8fHB7X69nr+8/PzadeuHYcPH5bns6tJ6qxmpL5qRuqrZqS+aqY260uv13PhwgWioqKwsrpxm7nRJeralJeXh6urK7m5uSajeYnrkzqrGamvmpH6qhmpr5oxV33JzWRCCCGEBZNELYQQQlgwSdS3wdbWlhkzZmBra2vuUOoNqbOakfqqGamvmpH6qhlz1ZdcoxZCCCEsmLSohRBCCAsmiVoIIYSwYJKohRBCCAsmifo2fPLJJ4SEhGBnZ0d0dDR//fWXuUOyWJs3b2bIkCH4+/ujUqn4+eefzR2SxZo9ezadO3fG2dkZb29vhg4dytGjR80dlsWaP38+ERERuLi44OLiQkxMDL///ru5w6o3Zs+ejUqlYuLEieYOxWLNnDkTlUplMvn6+tbZ8SVR36Lvv/+eiRMnMnXqVPbt20evXr0YNGiQybCcolJhYSGRkZHMmzfP3KFYvE2bNjF27Fi2b99OXFwcZWVl9O/fn8LCQnOHZpGaNWvG22+/ze7du9m9ezd33303999/P4cOHTJ3aBZv165dLFiwgIiICHOHYvHCwsJIS0szTomJiXV3cEXcki5duihjxowxKWvTpo3yyiuvmCmi+gNQVq5cae4w6o2MjAwFUDZt2mTuUOoNd3d35fPPPzd3GBYtPz9fadWqlRIXF6f06dNHeeGFF8wdksWaMWOGEhkZabbjS4v6FpSUlLBnzx769+9vUt6/f3+2bt1qpqhEQ5WbmwuAh4eHmSOxfDqdjmXLllFYWEhMTIy5w7FoY8eO5d5776Vfv37mDqVeOH78OP7+/oSEhPDoo49y6tSpOjt2oxs9qzZkZmai0+nw8fExKffx8SE9Pd1MUYmGSFEUJk2aRM+ePWnfvr25w7FYiYmJxMTEUFxcjJOTEytXrqRdu3bmDstiLVu2jL1797Jr1y5zh1IvdO3ala+//prWrVtz4cIF3nzzTbp3786hQ4fw9PS848eXRH0bVCqVybyiKFXKhLgd48aN48CBA/z999/mDsWihYaGkpCQQE5ODsuXL2fUqFFs2rRJkvU1pKam8sILL7Bu3Trs7OzMHU69MGjQIOPn8PBwYmJiaNGiBV999RWTJk2648eXRH0LmjRpgkajqdJ6zsjIqNLKFuJWjR8/nlWrVrF582aaNWtm7nAsmo2NDS1btgSgU6dO7Nq1i48++ojPPvvMzJFZnj179pCRkUF0dLSxTKfTsXnzZubNm4dWq0Wj0ZgxQsvn6OhIeHg4x48fr5PjyTXqW2BjY0N0dDRxcXEm5XFxcXTv3t1MUYmGQlEUxo0bx4oVK9iwYQMhISHmDqneURQFrVZr7jAsUmxsLImJiSQkJBinTp06MWLECBISEiRJV4NWqyUpKQk/P786OZ60qG/RpEmTGDlyJJ06dSImJoYFCxaQkpLCmDFjzB2aRSooKODEiRPG+eTkZBISEvDw8CAwMNCMkVmesWPH8t133/HLL7/g7Oxs7LlxdXXF3t7ezNFZnldffZVBgwYREBBAfn4+y5YtIz4+nrVr15o7NIvk7Oxc5X4HR0dHPD095T6I65g8eTJDhgwhMDCQjIwM3nzzTfLy8hg1alSdHF8S9S165JFHyMrKYtasWaSlpdG+fXvWrFlDUFCQuUOzSLt37+auu+4yzldc1xk1ahSLFy82U1SWaf78+QD07dvXpHzRokWMHj267gOycBcuXGDkyJGkpaXh6upKREQEa9eu5Z577jF3aKKBOHv2LMOHDyczMxMvLy+6devG9u3b6+zvvYyeJYQQQlgwuUYthBBCWDBJ1EIIIYQFk0QthBBCWDBJ1EIIIYQFk0QthBBCWDBJ1EIIIYQFk0QthBBCWDBJ1EIIIYQFk0QthLhjVCoVP//8s7nDEKJek0QtRAM1evRoVCpVlWngwIHmDk0IUQPyrm8hGrCBAweyaNEikzJbW1szRSOEuBXSohaiAbO1tcXX19dkcnd3Bwzd0vPnz2fQoEHY29sTEhLCjz/+aLJ9YmIid999N/b29nh6evLss89SUFBgss6XX35JWFgYtra2+Pn5MW7cOJPlmZmZPPDAAzg4ONCqVStWrVplXHbp0iVGjBiBl5cX9vb2tGrVqsqJhRCNnSRqIRqxadOm8eCDD7J//34ee+wxhg8fTlJSEgBFRUUMHDgQd3d3du3axY8//sj69etNEvH8+fMZO3Yszz77LImJiaxatYqWLVuaHOP111/n4Ycf5sCBAwwePJgRI0aQnZ1tPP7hw4f5/fffSUpKYv78+TRp0qTuKkCI+kARQjRIo0aNUjQajeLo6GgyzZo1S1EURQGUMWPGmGzTtWtX5bnnnlMURVEWLFiguLu7KwUFBcblq1evVtRqtZKenq4oiqL4+/srU6dOvW4MgPLaa68Z5wsKChSVSqX8/vvviqIoypAhQ5Qnnniidr6wEA2UXKMWogG76667jONbV/Dw8DB+jomJMVkWExNDQkICAElJSURGRuLo6Ghc3qNHD/R6PUePHkWlUnH+/HliY2NvGENERITxs6OjI87OzmRkZADw3HPP8eCDD7J371769+/P0KFD6d69+y19VyEaKknUQjRgjo6OVbqib0alUgGgKIrx87XWsbe3r9b+rK2tq2yr1+sBGDRoEGfOnGH16tWsX7+e2NhYxo4dy/vvv1+jmIVoyOQatRCN2Pbt26vMt2nTBoB27dqRkJBAYWGhcfmWLVtQq9W0bt0aZ2dngoOD+fPPP28rBi8vL0aPHs2SJUuYO3cuCxYsuK39CdHQSItaiAZMq9WSnp5uUmZlZWW8YevHH3+kU6dO9OzZk2+//ZadO3fyxRdfADBixAhmzJjBqFGjmDlzJhcvXmT8+PGMHDkSHx8fAGbOnMmYMWPw9vZm0KBB5Ofns2XLFsaPH1+t+KZPn050dDRhYWFotVp+++032rZtW4s1IET9J4laiAZs7dq1+Pn5mZSFhoZy5MgRwHBH9rJly3j++efx9fXl22+/pV27dgA4ODjwxx9/8MILL9C5c2ccHBx48MEH+eCDD4z7GjVqFMXFxXz44YdMnjyZJk2a8NBDD1U7PhsbG6ZMmcLp06ext7enV69eLFu2rBa+uRANh0pRFMXcQQgh6p5KpWLlypUMHTrU3KEIIW5ArlELIYQQFkwStRBCCGHB5Bq1EI2UXPUSon6QFrUQQghhwSRRCyGEEBZMErUQQghhwSRRCyGEEBZMErUQQghhwSRRCyGEEBZMErUQQghhwSRRCyGEEBZMErUQQghhwf4/w/kHfuj40p0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(\n",
    "        epochs_seen, examples_seen, train_values, val_values,\n",
    "        label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_values, linestyle=\"-.\",\n",
    "        label=f\"Validation {label}\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 73.85\n",
      "Validation accuracy: 68.00\n",
      "Test accuray:47.50\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "print(f\"Train accuracy: {train_accuracy*100:.2f}\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}\")\n",
    "print(f\"Test accuray:{test_accuracy*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the model to classify new texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(\n",
    "    text, model, tokenizer, device, max_length=None, \n",
    "    pad_token_id=50256\n",
    "):\n",
    "    model.eval()\n",
    "    \n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "    \n",
    "    input_ids = input_ids[:min(\n",
    "        max_length, supported_context_length\n",
    "    )]\n",
    "    \n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    \n",
    "    input_tensor = torch.tensor(\n",
    "        input_ids, device=device\n",
    "    ).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "        \n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    \n",
    "    return \"spam\" if predicted_label else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/zq32tf5j70sgdp__5gjt3jqh0000gn/T/ipykernel_38021/379311099.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"review_classifier.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
